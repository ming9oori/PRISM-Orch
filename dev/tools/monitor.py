"""
vLLM ì„œë²„ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import aiohttp
import time
import json
from datetime import datetime


async def monitor_server(base_url: str = "http://localhost:8000"):
    """ì„œë²„ ëª¨ë‹ˆí„°ë§"""
    print("ğŸ” vLLM Server Monitoring Started...")
    
    async with aiohttp.ClientSession() as session:
        while True:
            try:
                # í—¬ìŠ¤ì²´í¬
                async with session.get(f"{base_url}/health") as response:
                    health_data = await response.json()
                
                # í†µê³„ ì¡°íšŒ
                async with session.get(f"{base_url}/api/v1/stats") as response:
                    stats_data = await response.json()
                
                # í˜„ì¬ ì‹œê°„
                now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                # ëª¨ë‹ˆí„°ë§ ì •ë³´ ì¶œë ¥
                print(f"\n[{now}] Server Status:")
                print(f"  ğŸŸ¢ Status: {health_data['status']}")
                print(f"  ğŸ’¾ RAM Usage: {health_data['memory_usage']['ram_percent']:.1f}%")
                print(f"  ğŸ”¥ GPU Count: {health_data['gpu_count']}")
                print(f"  ğŸ“Š Active Requests: {health_data['active_requests']}")
                print(f"  ğŸ“ˆ Total Requests: {health_data['total_requests']}")
                print(f"  âš¡ Throughput: {health_data['throughput']:.2f} tokens/sec")
                print(f"  â° Uptime: {health_data['uptime']:.0f}s")
                
                if 'performance' in stats_data:
                    perf = stats_data['performance']
                    print(f"  ğŸ¯ Avg Tokens/Request: {perf['average_tokens_per_request']:.1f}")
                    print(f"  ğŸ“Š Total Tokens: {perf['total_tokens_generated']}")
                
            except Exception as e:
                print(f"âŒ Monitoring error: {e}")
            
            await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ëª¨ë‹ˆí„°ë§


if __name__ == "__main__":
    asyncio.run(monitor_server()) 